"use strict";(self.webpackChunktmp=self.webpackChunktmp||[]).push([[5730],{3905:function(e,n,t){t.d(n,{Zo:function(){return d},kt:function(){return m}});var r=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var l=r.createContext({}),c=function(e){var n=r.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=c(e.components);return r.createElement(l.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},h=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),h=c(t),m=o,p=h["".concat(l,".").concat(m)]||h[m]||u[m]||a;return t?r.createElement(p,i(i({ref:n},d),{},{components:t})):r.createElement(p,i({ref:n},d))}));function m(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,i=new Array(a);i[0]=h;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var c=2;c<a;c++)i[c]=t[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}h.displayName="MDXCreateElement"},4773:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return c},toc:function(){return d},default:function(){return h}});var r=t(7462),o=t(3366),a=(t(7294),t(3905)),i=["components"],s={sidebar_position:6},l="Overload Protection",c={unversionedId:"component/load",id:"component/load",title:"Overload Protection",description:"Why you need to downgrade your load",source:"@site/i18n/en/docusaurus-plugin-content-docs/current/component/load.md",sourceDirName:"component",slug:"/component/load",permalink:"/en/docs/component/load",tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"Circuit Breaker",permalink:"/en/docs/component/breaker"},next:{title:"Load Balancer",permalink:"/en/docs/component/balance"}},d=[{value:"Why you need to downgrade your load",id:"why-you-need-to-downgrade-your-load",children:[],level:3},{value:"What is Adaptive Load Shedding",id:"what-is-adaptive-load-shedding",children:[],level:3},{value:"Code implementation",id:"code-implementation",children:[],level:3},{value:"Reference",id:"reference",children:[],level:3}],u={toc:d};function h(e){var n=e.components,s=(0,o.Z)(e,i);return(0,a.kt)("wrapper",(0,r.Z)({},u,s,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"overload-protection"},"Overload Protection"),(0,a.kt)("h3",{id:"why-you-need-to-downgrade-your-load"},"Why you need to downgrade your load"),(0,a.kt)("p",null,"In a microservice cluster, the invocation link is complex, and as a service provider, it needs a mechanism to protect itself to prevent the caller from overwhelming itself with mindless invocations and ensure the high availability of its own services."),(0,a.kt)("p",null,"The most common protection mechanism is flow limiting mechanism, the premise of using flow limiter is to know the maximum number of concurrency that it can handle, and generally get the maximum number of concurrency by pressure testing before going online, and the flow limiting parameters of each interface are different in the daily request process, while the system has been constantly iterating and its processing capacity often changes, so it needs to pressure test and adjust the flow limiting parameters before going online each time. The parameters become very tedious."),(0,a.kt)("p",null,"So is there a more concise flow-limiting mechanism that can achieve maximum self-protection?"),(0,a.kt)("h3",{id:"what-is-adaptive-load-shedding"},"What is Adaptive Load Shedding"),(0,a.kt)("p",null,"Adaptive load shedding protects the service itself very intelligently and dynamically determines whether load shedding is needed based on the service's own system load."),(0,a.kt)("p",null,"Design Objective."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Ensure that the system does not get bogged down."),(0,a.kt)("li",{parentName:"ul"},"Maintain system throughput while the system is stable.")),(0,a.kt)("p",null,"The key then is how to measure the load on the service itself?"),(0,a.kt)("p",null,"Judging high load depends on two main indicators."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Whether the cpu is overloaded."),(0,a.kt)("li",{parentName:"ul"},"Whether the maximum concurrency is overloaded.")),(0,a.kt)("p",null,"When the above two points are met at the same time, it means that the service is in a high load state, then the adaptive down load."),(0,a.kt)("p",null,"It should also be noted that high concurrency scenarios cpu load, concurrency often fluctuate greatly, from the data we call this phenomenon burr, burr phenomenon may lead to the system has been frequent automatic down load operation, so we generally get the average value of indicators over a period of time to make the indicators more smooth. The implementation can be done by accurately recording the metrics over a period of time and then directly calculating the average value, but it takes up some system resources."),(0,a.kt)("p",null,"There is a statistical algorithm: exponential moving average, which can be used to estimate the local average of variables, so that the update of variables is related to the historical values over time, and the average can be estimated without recording all the historical local variables, which saves valuable server resources."),(0,a.kt)("p",null,"The principle of the sliding average algorithm is explained very clearly in this article."),(0,a.kt)("p",null,"The variable V is denoted as Vt at time t and \u03b8t is the value of the variable V at time t. That is, Vt = \u03b8t when the sliding average model is not used, and after using the sliding average model, Vt is updated by the following equation."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"Vt=\u03b2\u22c5Vt\u22121+(1\u2212\u03b2)\u22c5\u03b8t\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Vt = \u03b8t for \u03b2 = 0"),(0,a.kt)("li",{parentName:"ul"},"\u03b2 = 0.9, which is approximately the average of the last 10 \u03b8t values"),(0,a.kt)("li",{parentName:"ul"},"\u03b2 = 0.99, which is approximately the average of the last 100 \u03b8t values")),(0,a.kt)("h3",{id:"code-implementation"},"Code implementation"),(0,a.kt)("p",null,"Next, let's look at the code implementation of go-zero adaptive downgrading."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"load",src:t(5239).Z})),(0,a.kt)("p",null,"Adaptive load shedding interface definition."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go",metastring:'title="core/load/adaptiveshedder.go"',title:'"core/load/adaptiveshedder.go"'},"// Callback functions\nPromise interface {\n    // Callback to this function on successful request\n    Pass()\n    // Callback to this function on request failure\n    Fail()\n}\n\n// Definition of the drop-load interface\nShedder interface {\n    // Drop check\n    // 1. Allow the call, you need to manually execute Promise.accept()/reject() to report the actual execution task structure\n    // 2. Reject the call and it will return err: Service Overloaded Error ErrServiceOverloaded\n    Allow() (Promise, error)\n}\n")),(0,a.kt)("p",null,"The interface definition is very concise meaning that it is actually very simple to use, exposing an `Allow()(Promise,error) to the outside world."),(0,a.kt)("p",null,"Example of go-zero usage."),(0,a.kt)("p",null,"The business only needs to call the method to determine whether to dowload, if it is dowloaded then directly end the process, otherwise the execution of the business finally use the return value Promise according to the results of the implementation of the callback results can be."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"func UnarySheddingInterceptor(shedder load.Shedder, metrics *stat.Metrics) grpc.UnaryServerInterceptor {\n    ensureSheddingStat()\n\n    return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo,\n        handler grpc.UnaryHandler) (val interface{}, err error) {\n        sheddingStat.IncrementTotal()\n        var promise load.Promise\n        // Check for downgrades\n        promise, err = shedder.Allow()\n        // Drop load, record relevant logs and metrics\n        if err != nil {\n            metrics.AddDrop()\n            sheddingStat.IncrementDrop()\n            return\n        }\n        // Final callback execution result\n        defer func() {\n            // Execution Failure\n            if err == context.DeadlineExceeded {\n                promise.Fail()\n            // Successful implementation\n            } else {\n                sheddingStat.IncrementPass()\n                promise.Pass()\n            }\n        }()\n        // Implementation of business methods\n        return handler(ctx, req)\n    }\n}\n")),(0,a.kt)("p",null,"Definition of interface implementation classes."),(0,a.kt)("p",null,"There are three main types of properties"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"cpu load threshold: exceeding this value means the cpu is in a high load state."),(0,a.kt)("li",{parentName:"ul"},"Cooling period: If the service has been down loaded before, it will enter the cooling period, in order to prevent the load from being down during the down load process and immediately pressurize it to cause back and forth jitter. Because it takes some time to reduce the load, you should continue to check whether the number of concurrency exceeds the limit during the cooling-off period, and continue to discard requests if the limit is exceeded."),(0,a.kt)("li",{parentName:"ul"},"Concurrency number: the number of concurrency currently being processed, the average number of concurrency currently being processed, and the number of requests and response time in the recent period, the purpose is to calculate whether the number of concurrency currently being processed is greater than the maximum number of concurrency that can be carried by the system.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"// option parameter mode\nShedderOption func(opts *shedderOptions)\n\n// Optional configuration parameters\nshedderOptions struct {\n    // Sliding time window size\n    window time.Duration\n    // Number of sliding time windows\n    buckets int\n    // cpu load threshold\n    cpuThreshold int64\n}\n\n// Adaptive load drop structure, need to implement Shedder interface\nadaptiveShedder struct {\n    // cpu load threshold\n    // Higher than the threshold means high load needs to be downgraded to ensure service\n    cpuThreshold int64\n    // How many barrels in 1s\n    windows int64\n    // Number of concurrent\n    flying int64\n    // Sliding and smoothing the number of concurrent\n    avgFlying float64\n    // Spin locks, one service shares one drop load\n    // Locks must be applied when counting the number of requests currently being processed\n    // lossless concurrency for better performance\n    avgFlyingLock syncx.SpinLock\n    // Last rejection time\n    dropTime *syncx.AtomicDuration\n    // Have you been rejected recently\n    droppedRecently *syncx.AtomicBool\n    // Request statistics, with a sliding time window to record metrics over the most recent period\n    passCounter *collection.RollingWindow\n    // Response time statistics by sliding time windows to record metrics over the most recent period\n    rtCounter *collection.RollingWindow\n}\n")),(0,a.kt)("p",null,"Adaptive load shedding constructor\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"func NewAdaptiveShedder(opts ...ShedderOption) Shedder {\n    // To ensure code uniformity\n    // To return the default empty implementation when the developer closes, for code uniformity\n    // go-zero uses this design in many places, such as Breaker, the logging component\n    if !enabled.True() {\n        return newNopShedder()\n    }\n    // options mode sets optional configuration parameters\n    options := shedderOptions{\n        // Default statistics for the last 5s\n        window: defaultWindow,\n        // Default barrel quantity 50\n        buckets:      defaultBuckets,\n        // cpu load\n        cpuThreshold: defaultCpuThreshold,\n    }\n    for _, opt := range opts {\n        opt(&options)\n    }\n    // Calculate each window interval time, default is 100ms\n    bucketDuration := options.window / time.Duration(options.buckets)\n    return &adaptiveShedder{\n        // cpu load\n        cpuThreshold:    options.cpuThreshold,\n        // How many sliding window cells are included in 1s time\n        windows:         int64(time.Second / bucketDuration),\n        // Last rejection time\n        dropTime:        syncx.NewAtomicDuration(),\n        // Have you been rejected recently\n        droppedRecently: syncx.NewAtomicBool(),\n        // qps statistics, sliding time window\n        // Ignore the current writing window (bucket), incomplete time period may lead to data anomalies\n        passCounter: collection.NewRollingWindow(options.buckets, bucketDuration,\n            collection.IgnoreCurrentBucket()),\n        // Response time statistics, sliding time window\n        // Ignore the current writing window (bucket), incomplete time period may lead to data anomalies\n        rtCounter: collection.NewRollingWindow(options.buckets, bucketDuration,\n            collection.IgnoreCurrentBucket()),\n    }\n}\n\n")),(0,a.kt)("p",null,"Drop Load Check Allow()."),(0,a.kt)("p",null,"Check whether the current request should be discarded, is discarded business side needs to directly interrupt the request to protect the service, also means that the downgrade takes effect while entering the cooling off period. If it is allowed, it returns promise and waits for the business side to execute the callback function to perform the metrics statistics."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"// Down load check\nfunc (as *adaptiveShedder) Allow() (Promise, error) {\n    // Check if the request was discarded\n    if as.shouldDrop() {\n        // Set drop time\n        as.dropTime.Set(timex.Now())\n        // Recently dropped\n        as.droppedRecently.Set(true)\n        // Return to Overload\n        return nil, ErrServiceOverloaded\n    }\n    // Number of requests being processed plus 1\n    as.addFlying(1)\n    // Each allowed request here returns a new promise object\n    // The promise holds the drop pointer object internally\n    return &promise{\n        start:   timex.Now(),\n        shedder: as,\n    }, nil\n}\n")),(0,a.kt)("p",null,"Check if shouldDrop() should be dropped."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},'// Whether the request should be discarded\nfunc (as *adaptiveShedder) shouldDrop() bool {\n    // The current cpu load exceeds the threshold\n    // Service should continue to check load and try to discard requests while on cooldown\n    if as.systemOverloaded() || as.stillHot() {\n        // Check if the concurrency being processed exceeds the current maximum number of concurrency that can be carried\n       // Discard the request if it exceeds it\n        if as.highThru() {\n            flying := atomic.LoadInt64(&as.flying)\n            as.avgFlyingLock.Lock()\n            avgFlying := as.avgFlying\n            as.avgFlyingLock.Unlock()\n            msg := fmt.Sprintf(\n                "dropreq, cpu: %d, maxPass: %d, minRt: %.2f, hot: %t, flying: %d, avgFlying: %.2f",\n                stat.CpuUsage(), as.maxPass(), as.minRt(), as.stillHot(), flying, avgFlying)\n            logx.Error(msg)\n            stat.Report(msg)\n            return true\n        }\n    }\n    return false\n}\n')),(0,a.kt)("p",null,"cpu threshold check systemOverloaded()."),(0,a.kt)("p",null,"The cpu load value calculation algorithm uses the sliding average algorithm to prevent burr phenomenon. Sampling every 250ms \u03b2 is 0.95, which is roughly equivalent to the average of 20 cpu loadings in history, with a time period of about 5s."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"// Is the cpu overloaded\nfunc (as *adaptiveShedder) systemOverloaded() bool {\n    return systemOverloadChecker(as.cpuThreshold)\n}\n\n// cpu check function\nsystemOverloadChecker = func(cpuThreshold int64) bool {\n        return stat.CpuUsage() >= cpuThreshold\n}\n\n// cpu sliding average\ncurUsage := internal.RefreshCpu()\nprevUsage := atomic.LoadInt64(&cpuUsage)\n// cpu = cpu\u1d57\u207b\xb9 * beta + cpu\u1d57 * (1 - beta)\n// Sliding average algorithm\nusage := int64(float64(prevUsage)*beta + float64(curUsage)*(1-beta))\natomic.StoreInt64(&cpuUsage, usage)\n")),(0,a.kt)("p",null,"Check if it is stillHot:"),(0,a.kt)("p",null,"Determine whether the current system is in the cooling period, if in the cooling period, you should continue to try to check whether to discard the request. The main purpose is to prevent the system in the process of overload recovery before the load has come down, and immediately increase the pressure again resulting in back and forth jitter, at this time should try to continue to discard the request."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"func (as *adaptiveShedder) stillHot() bool {\n    // No recent requests have been discarded\n    // means the service is working\n    if !as.droppedRecently.True() {\n        return false\n    }\n    // Not in cooling period\n    dropTime := as.dropTime.Load()\n    if dropTime == 0 {\n        return false\n    }\n    // Cooling time default is 1s\n    hot := timex.Since(dropTime) < coolOffDuration\n    // Not in cooling-off period, normal processing of requests in progress\n    if !hot {\n        // Reset drop records\n        as.droppedRecently.Set(false)\n    }\n\n    return hot\n}\n")),(0,a.kt)("p",null,"Check the number of concurrency currently being processed highThru()."),(0,a.kt)("p",null,"Once the number of concurrency currently being processed > the concurrency carrying limit, then it enters the down load state."),(0,a.kt)("p",null,"Why do we need to add a lock here? Because adaptive downgrading is used globally to ensure that the concurrency average is correct."),(0,a.kt)("p",null,"Why do we need to add spin locks here? Because concurrency processing can be performed without blocking other goroutines, and lock-free concurrency can be used to improve performance."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"func (as *adaptiveShedder) highThru() bool {\n    // Add lock\n    as.avgFlyingLock.Lock()\n    // Get the sliding average\n    // Update at the end of each request\n    avgFlying := as.avgFlying\n    // Unlock\n    as.avgFlyingLock.Unlock()\n    // Maximum concurrency of the system at this time\n    maxFlight := as.maxFlight()\n    // Whether the number of concurrency being processed and the average concurrency is greater than the system's maximum concurrency\n    return int64(avgFlying) > maxFlight && atomic.LoadInt64(&as.flying) > maxFlight\n}\n")),(0,a.kt)("p",null,"How can we get the number of concurrency being processed and the average number of concurrency?"),(0,a.kt)("p",null,"The current concurrency count is actually very simple: +1 concurrency for each allowed request, -1 for the promise object callback after the request is completed, and the average concurrency can be solved using the sliding average algorithm."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"type promise struct {\n    // Request start time\n    // Statistics on request processing time\n    start   time.Duration\n    shedder *adaptiveShedder\n}\n\nfunc (p *promise) Fail() {\n    // End of request, number of requests currently being processed - 1\n    p.shedder.addFlying(-1)\n}\n\nfunc (p *promise) Pass() {\n    // Response time in milliseconds\n    rt := float64(timex.Since(p.start)) / float64(time.Millisecond)\n    // End of request, number of requests currently being processed - 1\n    p.shedder.addFlying(-1)\n    p.shedder.rtCounter.Add(math.Ceil(rt))\n    p.shedder.passCounter.Add(1)\n}\n\nfunc (as *adaptiveShedder) addFlying(delta int64) {\n    flying := atomic.AddInt64(&as.flying, delta)\n    // When the request is finished, count the concurrency of requests currently being processed\n    if delta < 0 {\n        as.avgFlyingLock.Lock()\n        // Estimate the average number of requests for the current service over a recent period of time\n        as.avgFlying = as.avgFlying*flyingBeta + float64(flying)*(1-flyingBeta)\n        as.avgFlyingLock.Unlock()\n    }\n}\n\n")),(0,a.kt)("p",null,"It is not enough to get the current system count, we also need to know the maximum number of concurrent requests that the system can handle, i.e., the maximum number of concurrent requests."),(0,a.kt)("p",null,"The number of requests passed and the response time are both achieved by a sliding window, which can be found in the article on adaptive fusers."),(0,a.kt)("p",null,"The maximum concurrency of the current system = the maximum number of passes per unit time of the window * the minimum response time per unit time of the window."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},"// Calculate the maximum number of concurrency of the system per second\n// Maximum concurrency = maximum requests (qps) * minimum response time (rt)\nfunc (as *adaptiveShedder) maxFlight() int64 {\n    // windows = buckets per second\n    // maxQPS = maxPASS * windows\n    // minRT = min average response time in milliseconds\n    // maxQPS * minRT / milliseconds_per_second\n    // as.maxPass() * as.windows - maximum qps per bucket * number of buckets contained in 1s\n    // as.minRt()/1e3 - the smallest average response time of all buckets in the window / 1000ms here to convert to seconds\n    return int64(math.Max(1, float64(as.maxPass()*as.windows)*(as.minRt()/1e3)))\n}\n\n// Sliding time window with multiple buckets\n// Find the one with the highest number of requests\n// Each bucket takes up internal ms\n// qps refers to the number of requests in 1s, qps: maxPass * time.Second/internal\nfunc (as *adaptiveShedder) maxPass() int64 {\n    var result float64 = 1\n    // The bucket with the highest number of requests in the current time window\n    as.passCounter.Reduce(func(b *collection.Bucket) {\n        if b.Sum > result {\n            result = b.Sum\n        }\n    })\n\n    return int64(result)\n}\n\n// Sliding time window with multiple buckets\n// Calculate the minimum average response time\n// because it is necessary to calculate the maximum number of concurrency that the system can handle in a recent period of time\nfunc (as *adaptiveShedder) minRt() float64 {\n    // Default is 1000ms\n    result := defaultMinRt\n\n    as.rtCounter.Reduce(func(b *collection.Bucket) {\n        if b.Count <= 0 {\n            return\n        }\n        // Average response time for requests\n        avg := math.Round(b.Sum / float64(b.Count))\n        if avg < result {\n            result = avg\n        }\n    })\n\n    return result\n}\n")),(0,a.kt)("h3",{id:"reference"},"Reference"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://queue.acm.org/detail.cfm?id=3022184"},"Google BBR Congestion Control Algorithm")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.cnblogs.com/wuliytTaotao/p/9479958.html"},"Principle of sliding average algorithm")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://go-zero.dev/cn/loadshedding.html"},"go-zero adaptive load shedding")))}h.isMDXComponent=!0},5239:function(e,n,t){n.Z=t.p+"assets/images/load-85cf3a1f44a768671097af6ef13b2ac1.png"}}]);